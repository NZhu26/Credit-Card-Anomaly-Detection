{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a6ae80-aed0-4a69-bb6d-ee66603499be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "class Local_Outlier_Factor:\n",
    "    def __init__(self, n_neighbors, metric, datasize):\n",
    "        self.k = n_neighbors\n",
    "        self.distanceType = metric\n",
    "        self.lofScores = []\n",
    "        self.threshold = None\n",
    "        self.neighborInfo = [0] * datasize  # contains list of tuples with information about neighbors for each datapoint [(neigbor1Distance, neighbor1Index), \n",
    "                                            # (neigbor2Distance, neighbor2Index) ...]\n",
    "            \n",
    "    # Assumes that 0 is negative and 1 is positive and the matrix will be 2 x 2\n",
    "    def confusionMatrix(self, trueLabels, predictedLabels):\n",
    "        matrix = [[0, 0], [0, 0]]\n",
    "        for i in range(len(trueLabels)):\n",
    "            matrix[trueLabels[i]][predictedLabels[i]] += 1\n",
    "        return np.array(matrix)\n",
    "\n",
    "    # input precision, recall, f1score, or parts\n",
    "    def matrixScores(self, matrix, scoreType):\n",
    "        neg, pos = matrix\n",
    "        tn, fp = neg\n",
    "        fn, tp = pos\n",
    "        if scoreType == \"parts\":\n",
    "            return [tn, fn, fp, tp]\n",
    "        if scoreType == \"precision\":\n",
    "            if tp == 0:\n",
    "                return 0\n",
    "            return tp/(tp+fp)\n",
    "        if scoreType == \"recall\":\n",
    "            if tp == 0:\n",
    "                return 0\n",
    "            return tp/(tp+fn)\n",
    "        if scoreType == \"f1score\":\n",
    "            if tp == 0:\n",
    "                return 0\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "            return 2 * ((precision * recall)/(precision + recall))\n",
    "        else:\n",
    "            print(\"Please enter a valid scoreType\")\n",
    "            \n",
    "\n",
    "    def distance(self, a, b):\n",
    "        if self.distanceType == \"euclidean\":\n",
    "            try: \n",
    "                s = 0\n",
    "                if type(a) != type(b) or len(a) != len(b):\n",
    "                    raise Exception(\"The inputs a and b need to be same type and equal length\") \n",
    "                for i in range(len(a)):\n",
    "                    s += (a[i] - b[i])**2\n",
    "                return math.sqrt(s)\n",
    "            except Exception as e:\n",
    "                print(f\"Exception: {e}\")\n",
    "        elif self.distanceType == \"manhattan\":\n",
    "            try: \n",
    "                s = 0\n",
    "                if type(a) != type(b) or len(a) != len(b):\n",
    "                    raise Exception(\"The inputs a and b need to be same type and equal length\") \n",
    "                for i in range(len(a)):\n",
    "                    s += abs(a[i] - b[i])\n",
    "                return s\n",
    "            except Exception as e:\n",
    "                print(f\"Exception: {e}\")\n",
    "        else:\n",
    "            raise Exception(\"Please input a valid distance type into the LocalOutlierFactor object.\")\n",
    "\n",
    "    def kNeighbors(self, datapoints, query):\n",
    "        neighbors = [0] * (self.k+1)\n",
    "        neighbor = 0\n",
    "        worstBest = float('inf')\n",
    "        for i in range(len(datapoints)):\n",
    "            d = self.distance(datapoints[i], query)\n",
    "            if d < worstBest:\n",
    "                if neighbor < self.k+1:\n",
    "                    neighbors[neighbor] = (d, i)\n",
    "                    neighbor += 1\n",
    "                else:\n",
    "                    maximum = float('-inf')\n",
    "                    maxIndex = 0\n",
    "                    for j in range(len(neighbors)):\n",
    "                        if neighbors[j][0] > maximum:\n",
    "                            maximum = neighbors[j][0]\n",
    "                            maxIndex = j\n",
    "                    worstBest = maximum\n",
    "                    if d < worstBest:\n",
    "                        neighbors[maxIndex] = (d, i)\n",
    "        neighbors.sort()\n",
    "        return neighbors[1:]\n",
    "\n",
    "    def reachabilityDistance(self, distance, kDistance):\n",
    "        return max(distance, kDistance)\n",
    "\n",
    "    def localReachabilityDensity(self, datapoints, neighbors):\n",
    "        foundNeighbors = set()\n",
    "        reachabilityDistanceSum = 0\n",
    "        # Calculates local reachability density\n",
    "        for i in range(len(neighbors)):\n",
    "            distanceToNeighbor = neighbors[i][0]\n",
    "            neighborIndex = neighbors[i][1]\n",
    "            reachabilityDistanceSum += self.reachabilityDistance(distanceToNeighbor, self.neighborInfo[neighborIndex][-1][0])\n",
    "        avgReachabilityDistance = reachabilityDistanceSum / self.k\n",
    "        return 1.0 / (avgReachabilityDistance + 1e-10)\n",
    "\n",
    "    def localOutlierFactor(self, datapoints, query, neighbors):\n",
    "        lrdQuery = self.localReachabilityDensity(datapoints, self.neighborInfo[query])\n",
    "        \n",
    "        lrdNeighborsSum = 0\n",
    "        for i in range(len(neighbors)):\n",
    "            neighborIndex = neighbors[i][1]\n",
    "            lrdNeighborsSum += self.localReachabilityDensity(datapoints, self.neighborInfo[neighborIndex])\n",
    "        avgLRDNeighbors = lrdNeighborsSum / self.k\n",
    "        \n",
    "        LOF = avgLRDNeighbors / lrdQuery\n",
    "        return LOF\n",
    "    \n",
    "    # returns start and end indices of chunks of data\n",
    "    # ex. [[0, 10], [10, 20]] if the number of datapoints is 20 and 2 chunks are needed\n",
    "    def getChunks(self, numDatapoints, numChunks):\n",
    "        chunkSize = numDatapoints//numChunks\n",
    "        res = []\n",
    "        startIndex = 0\n",
    "        if numDatapoints%numChunks == 0: \n",
    "            while startIndex < numDatapoints:\n",
    "                res.append([startIndex, startIndex+chunkSize])\n",
    "                startIndex += chunkSize\n",
    "        else:\n",
    "            while startIndex < numDatapoints-chunkSize:\n",
    "                res.append([startIndex, startIndex+chunkSize])\n",
    "                startIndex += chunkSize\n",
    "            res[-1][1] = numDatapoints\n",
    "        return res\n",
    "        \n",
    "    def parallel_method_call(self, datapoints, indices):\n",
    "        res = []\n",
    "        for i in range(indices[0], indices[1]):\n",
    "            res.append([i, self.kNeighbors(datapoints, datapoints[i])])\n",
    "        return res\n",
    "        \n",
    "    def createOutlierFactor(self, datapoints, cores = 1):\n",
    "        chunkIndices = self.getChunks(len(datapoints), cores) # indices of data for each core\n",
    "        \n",
    "        # Calculates information for each neighbor based on the n_neighbors specified within the Local_Outlier_Factor object.\n",
    "        results = Parallel(n_jobs=-1)(delayed(self.parallel_method_call)(datapoints, chunkIndices[i]) for i in range(len(chunkIndices)))\n",
    "        \n",
    "        for i in range(len(results)):\n",
    "            for j in range(len(results[i])):\n",
    "                self.neighborInfo[results[i][j][0]] = results[i][j][1]\n",
    "        \n",
    "        # Calculates the local reachability factors for each datapoint and puts it within a list\n",
    "        for i in range(len(datapoints)):\n",
    "            self.lofScores.append(self.localOutlierFactor(datapoints, i, self.neighborInfo[i]))\n",
    "        return np.array(self.lofScores)\n",
    "    \n",
    "    def findThreshold(self, trueLabels):\n",
    "        if not self.lofScores:\n",
    "            raise Exception(\"Please calculate local outlier factors first before trying to find a threshold value for them.\")\n",
    "        highestLOF = max(self.lofScores)\n",
    "        curThreshold = min(self.lofScores)\n",
    "        bestThresholdPrecision = float('-inf')\n",
    "        bestThreshold = curThreshold\n",
    "        while curThreshold < highestLOF:\n",
    "            predicted = []\n",
    "            for lof in self.lofScores:\n",
    "                if lof < curThreshold:\n",
    "                    predicted.append(1)\n",
    "                else:\n",
    "                    predicted.append(0)\n",
    "            precision = self.matrixScores(self.confusionMatrix(trueLabels, predicted), \"precision\")\n",
    "            if precision > bestThresholdPrecision:\n",
    "                bestThresholdPrecision = precision\n",
    "                bestThreshold = curThreshold\n",
    "            curThreshold += 0.1\n",
    "        self.threshold = bestThreshold\n",
    "    \n",
    "    def predict(self, datapoints, newData, cores = 1):\n",
    "        if newData:\n",
    "            self.lofScores = []\n",
    "            self.neighborInfo = [0] * len(datapoints)\n",
    "            self.createOutlierFactor(datapoints, cores)\n",
    "            predicted = []\n",
    "            for lof in self.lofScores:\n",
    "                if lof > self.threshold:\n",
    "                    predicted.append(1)\n",
    "                else:\n",
    "                    predicted.append(0)\n",
    "            return predicted\n",
    "        else:\n",
    "            predicted = []\n",
    "            for lof in self.lofScores:\n",
    "                if lof > self.threshold:\n",
    "                    predicted.append(1)\n",
    "                else:\n",
    "                    predicted.append(0)\n",
    "            return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f84365-32a7-4dad-8f3f-b7e75ccc931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "# Assumes that 0 is negative and 1 is positive and the matrix will be 2 x 2\n",
    "def confusionMatrixMD(trueLabels, predictedLabels):\n",
    "    matrix = [[0, 0], [0, 0]]\n",
    "    for i in range(len(trueLabels)):\n",
    "        matrix[trueLabels[i]][predictedLabels[i]] += 1\n",
    "    return np.array(matrix)\n",
    "\n",
    "# input precision, recall, f1score, or parts\n",
    "def matrixScoresMD(matrix, scoreType):\n",
    "    neg, pos = matrix\n",
    "    tn, fp = neg\n",
    "    fn, tp = pos\n",
    "    if scoreType == \"parts\":\n",
    "        return [tn, fn, fp, tp]\n",
    "    if scoreType == \"precision\":\n",
    "        if tp == 0:\n",
    "            return 0\n",
    "        return tp/(tp+fp)\n",
    "    if scoreType == \"recall\":\n",
    "        if tp == 0:\n",
    "            return 0\n",
    "        return tp/(tp+fn)\n",
    "    if scoreType == \"f1score\":\n",
    "        if tp == 0:\n",
    "            return 0\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        return 2 * ((precision * recall)/(precision + recall))\n",
    "    else:\n",
    "        print(\"Please enter a valid scoreType\")\n",
    "\n",
    "\"\"\"\n",
    "Compute the Mahalanobis Distance between each row of x and the data\n",
    "points: matrix of data that contains the points for which you want the Mahalanobis distance\n",
    "distribution: ndarray of the distribution from which Mahalanobis distance of each observation of a point in points is to be computed.\n",
    "\"\"\"\n",
    "def mahalanobisDistance(points, distribution):\n",
    "    colMeans = []\n",
    "    for col in distribution.T:\n",
    "        colMeans.append(np.mean(col))\n",
    "    points_minus_mean = np.copy(points)\n",
    "    for i in range(len(points)):\n",
    "        for j in range(len(points[i])):\n",
    "            points_minus_mean[i][j] = points[i][j] - colMeans[j]\n",
    "    covarianceMatrix = np.cov(distribution.T)\n",
    "    inverseCovarianceMatrix = linalg.inv(covarianceMatrix)\n",
    "    mahalanobisDistanceMatrix = np.dot(np.dot(points_minus_mean, inverseCovarianceMatrix), points_minus_mean.T)\n",
    "    return mahalanobisDistanceMatrix.diagonal()\n",
    "\n",
    "# finds best threshold value for data\n",
    "def findThresholdMD(mahalanobisDistances, trueLabels):\n",
    "    longestDistance = max(mahalanobisDistances)\n",
    "    curThreshold = 0\n",
    "    bestThresholdPrecision = 0\n",
    "    bestThreshold = curThreshold\n",
    "    while curThreshold < longestDistance:\n",
    "        predicted = []\n",
    "        for distance in mahalanobisDistances:\n",
    "            if distance > curThreshold:\n",
    "                predicted.append(1)\n",
    "            else:\n",
    "                predicted.append(0)\n",
    "        precision = matrixScoresMD(confusionMatrixMD(trueLabels, predicted), \"precision\")\n",
    "        if precision > bestThresholdPrecision:\n",
    "            bestThresholdPrecision = precision\n",
    "            bestThreshold = curThreshold\n",
    "        curThreshold += 1\n",
    "    return bestThreshold\n",
    "\n",
    "def predictMD(threshold, data):\n",
    "    mahalanobisDistances = mahalanobisDistance(data, data)\n",
    "    predicted = []\n",
    "    for distance in mahalanobisDistances:\n",
    "        if distance > threshold:\n",
    "            predicted.append(1)\n",
    "        else:\n",
    "            predicted.append(0)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182db6ed-edcf-4647-8ae8-f4b388495cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13deac-3030-4ad4-8af6-8523805254ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
